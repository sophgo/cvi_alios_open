// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_CVIMODEL_CVI_MODEL_H_
#define FLATBUFFERS_GENERATED_CVIMODEL_CVI_MODEL_H_

#include "flatbuffers/flatbuffers.h"

namespace cvi {
namespace model {

struct Version;

struct Shape;
struct ShapeBuilder;

struct QuantInfo;
struct QuantInfoBuilder;

struct Tensor;
struct TensorBuilder;

struct Weight;
struct WeightBuilder;

struct PreProcessHints;
struct PreProcessHintsBuilder;

struct PostProcessHints;
struct PostProcessHintsBuilder;

struct TpuRoutine;
struct TpuRoutineBuilder;

struct CpuRoutine;
struct CpuRoutineBuilder;

struct Routine;
struct RoutineBuilder;

struct Program;
struct ProgramBuilder;

struct Section;
struct SectionBuilder;

struct Model;
struct ModelBuilder;

///
/// General Descriptions
/// Model:
///   A model is generated from one NN model, it contains one or more
///   `Segment`s, each `Segment` could be either a TPU segment or a CPU
///   segment. A Model takes one or more `Tensor`s as input, and produces
///   one or more `Tensor's as output. Along with `Segment`s, a list of
///   `Memory` and a list of `Tensor` are provided.
/// Segment:
///   A segment is a program running on a certain type of engine (`TPU` or
///   `CPU`), which takes a list of `Tensor`s as input, and produces a list
///   of `Tensor`s as output.
/// Memory:
///   Memorys are memory spaces that are holding actual data. `Memory`s are
///   passed among `Segment`s or passed as input/output of the `Model`. When
///   `size` field is present, `size` specifies the space that is needed. When
///   `size` is not present (or set to -1), the memory is dynamic shaped, and
///   runtime needs to derive size for the `Memory` after input shape has been
///   set.
/// Tensor:
///   Tensor is an abstract description of a chunk of data, with a specific
///   data type (DType) and shape, as well optional strides. Each Tensor is
///   bound to a `Memory` (with memory_id). When present, `offset` is used to
///   describe the relative address of the tensor within the `Memory`.
/// InputTensor/OutputTensor:
///   To describe the input/output tensors of the model, by referencing
///   tensor_id in tensor_list, along with preprocess_hints/postprocess_hints.
///   `preprocess_hints` are information on how input data should be processed
///   before passing to the model, and `postprocess_hints` are information on
///   how output data should be processed.
/// Program:
///   Program is the executive part of a `Segment`, 2 types of Programs are
///   defined, TpuProgram and CpuProgram.
/// TpuProgram:
///   A TpuProgram consists of `Cmdbuf` and `Weight`. To support different
///   batch_size or input image dimesions, multiple `Cmdbuf`s may be needed,
///   with each `Cmdbuf` handling one fixed batch_size and image dims. i.e.
///   on `Cmdbuf` level dynamic shape are not supported.
/// Cmdbuf:
///   Cmdbuf is a sequence of TPU instuctions.
/// Weight:
///   Weight is the trained weight data.
/// CpuProgram:
///   A CpuProgram consists of a cpu function and `Weight`. A function could
///   be either a runtime build-in function, or a plug-in library registered
///   along with the Model in the CpuFunction section.
/// CpuFunction:
///   A CpuFunction is a plug-in library registered along with the Model.
///
enum MajorVersion {
  MajorVersion_value = 1,
  MajorVersion_MIN = MajorVersion_value,
  MajorVersion_MAX = MajorVersion_value
};

inline const MajorVersion (&EnumValuesMajorVersion())[1] {
  static const MajorVersion values[] = {
    MajorVersion_value
  };
  return values;
}

inline const char * const *EnumNamesMajorVersion() {
  static const char * const names[2] = {
    "value",
    nullptr
  };
  return names;
}

inline const char *EnumNameMajorVersion(MajorVersion e) {
  if (flatbuffers::IsOutRange(e, MajorVersion_value, MajorVersion_value)) return "";
  const size_t index = static_cast<size_t>(e) - static_cast<size_t>(MajorVersion_value);
  return EnumNamesMajorVersion()[index];
}

enum MinorVersion {
  MinorVersion_value = 4,
  MinorVersion_MIN = MinorVersion_value,
  MinorVersion_MAX = MinorVersion_value
};

inline const MinorVersion (&EnumValuesMinorVersion())[1] {
  static const MinorVersion values[] = {
    MinorVersion_value
  };
  return values;
}

inline const char * const *EnumNamesMinorVersion() {
  static const char * const names[2] = {
    "value",
    nullptr
  };
  return names;
}

inline const char *EnumNameMinorVersion(MinorVersion e) {
  if (flatbuffers::IsOutRange(e, MinorVersion_value, MinorVersion_value)) return "";
  const size_t index = static_cast<size_t>(e) - static_cast<size_t>(MinorVersion_value);
  return EnumNamesMinorVersion()[index];
}

enum SubMinorVersion {
  SubMinorVersion_value = 0,
  SubMinorVersion_MIN = SubMinorVersion_value,
  SubMinorVersion_MAX = SubMinorVersion_value
};

inline const SubMinorVersion (&EnumValuesSubMinorVersion())[1] {
  static const SubMinorVersion values[] = {
    SubMinorVersion_value
  };
  return values;
}

inline const char * const *EnumNamesSubMinorVersion() {
  static const char * const names[2] = {
    "value",
    nullptr
  };
  return names;
}

inline const char *EnumNameSubMinorVersion(SubMinorVersion e) {
  if (flatbuffers::IsOutRange(e, SubMinorVersion_value, SubMinorVersion_value)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesSubMinorVersion()[index];
}

enum DType {
  DType_FP32 = 0,
  DType_INT32 = 1,
  DType_UINT32 = 2,
  DType_BF16 = 3,
  DType_INT16 = 4,
  DType_UINT16 = 5,
  DType_INT8 = 6,
  DType_UINT8 = 7,
  DType_MIN = DType_FP32,
  DType_MAX = DType_UINT8
};

inline const DType (&EnumValuesDType())[8] {
  static const DType values[] = {
    DType_FP32,
    DType_INT32,
    DType_UINT32,
    DType_BF16,
    DType_INT16,
    DType_UINT16,
    DType_INT8,
    DType_UINT8
  };
  return values;
}

inline const char * const *EnumNamesDType() {
  static const char * const names[9] = {
    "FP32",
    "INT32",
    "UINT32",
    "BF16",
    "INT16",
    "UINT16",
    "INT8",
    "UINT8",
    nullptr
  };
  return names;
}

inline const char *EnumNameDType(DType e) {
  if (flatbuffers::IsOutRange(e, DType_FP32, DType_UINT8)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesDType()[index];
}

enum QuantType {
  QuantType_NONE = 0,
  QuantType_BF16 = 1,
  QuantType_INT8_SYM = 2,
  QuantType_INT8_ASYM = 3,
  QuantType_MIN = QuantType_NONE,
  QuantType_MAX = QuantType_INT8_ASYM
};

inline const QuantType (&EnumValuesQuantType())[4] {
  static const QuantType values[] = {
    QuantType_NONE,
    QuantType_BF16,
    QuantType_INT8_SYM,
    QuantType_INT8_ASYM
  };
  return values;
}

inline const char * const *EnumNamesQuantType() {
  static const char * const names[5] = {
    "NONE",
    "BF16",
    "INT8_SYM",
    "INT8_ASYM",
    nullptr
  };
  return names;
}

inline const char *EnumNameQuantType(QuantType e) {
  if (flatbuffers::IsOutRange(e, QuantType_NONE, QuantType_INT8_ASYM)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesQuantType()[index];
}

enum RoutineType {
  RoutineType_TPU = 0,
  RoutineType_CPU = 1,
  RoutineType_MIN = RoutineType_TPU,
  RoutineType_MAX = RoutineType_CPU
};

inline const RoutineType (&EnumValuesRoutineType())[2] {
  static const RoutineType values[] = {
    RoutineType_TPU,
    RoutineType_CPU
  };
  return values;
}

inline const char * const *EnumNamesRoutineType() {
  static const char * const names[3] = {
    "TPU",
    "CPU",
    nullptr
  };
  return names;
}

inline const char *EnumNameRoutineType(RoutineType e) {
  if (flatbuffers::IsOutRange(e, RoutineType_TPU, RoutineType_CPU)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesRoutineType()[index];
}

enum SectionType {
  SectionType_WEIGHT = 0,
  SectionType_CMDBUF = 1,
  SectionType_FUNC_X86 = 2,
  SectionType_FUNC_AARCH64 = 3,
  SectionType_DMABUF = 4,
  SectionType_MIN = SectionType_WEIGHT,
  SectionType_MAX = SectionType_DMABUF
};

inline const SectionType (&EnumValuesSectionType())[5] {
  static const SectionType values[] = {
    SectionType_WEIGHT,
    SectionType_CMDBUF,
    SectionType_FUNC_X86,
    SectionType_FUNC_AARCH64,
    SectionType_DMABUF
  };
  return values;
}

inline const char * const *EnumNamesSectionType() {
  static const char * const names[6] = {
    "WEIGHT",
    "CMDBUF",
    "FUNC_X86",
    "FUNC_AARCH64",
    "DMABUF",
    nullptr
  };
  return names;
}

inline const char *EnumNameSectionType(SectionType e) {
  if (flatbuffers::IsOutRange(e, SectionType_WEIGHT, SectionType_DMABUF)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesSectionType()[index];
}

FLATBUFFERS_MANUALLY_ALIGNED_STRUCT(1) Version FLATBUFFERS_FINAL_CLASS {
 private:
  uint8_t major__;
  uint8_t minor__;
  uint8_t sub_minor_;

 public:
  Version() {
    memset(static_cast<void *>(this), 0, sizeof(Version));
  }
  Version(uint8_t _major_, uint8_t _minor_, uint8_t _sub_minor)
      : major__(flatbuffers::EndianScalar(_major_)),
        minor__(flatbuffers::EndianScalar(_minor_)),
        sub_minor_(flatbuffers::EndianScalar(_sub_minor)) {
  }
  uint8_t major_() const {
    return flatbuffers::EndianScalar(major__);
  }
  uint8_t minor_() const {
    return flatbuffers::EndianScalar(minor__);
  }
  uint8_t sub_minor() const {
    return flatbuffers::EndianScalar(sub_minor_);
  }
};
FLATBUFFERS_STRUCT_END(Version, 3);

/// -1 is used to indicate that dim is dynamic
struct Shape FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ShapeBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DIM = 4
  };
  const flatbuffers::Vector<int64_t> *dim() const {
    return GetPointer<const flatbuffers::Vector<int64_t> *>(VT_DIM);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffsetRequired(verifier, VT_DIM) &&
           verifier.VerifyVector(dim()) &&
           verifier.EndTable();
  }
};

struct ShapeBuilder {
  typedef Shape Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_dim(flatbuffers::Offset<flatbuffers::Vector<int64_t>> dim) {
    fbb_.AddOffset(Shape::VT_DIM, dim);
  }
  explicit ShapeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ShapeBuilder &operator=(const ShapeBuilder &);
  flatbuffers::Offset<Shape> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Shape>(end);
    fbb_.Required(o, Shape::VT_DIM);
    return o;
  }
};

inline flatbuffers::Offset<Shape> CreateShape(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> dim = 0) {
  ShapeBuilder builder_(_fbb);
  builder_.add_dim(dim);
  return builder_.Finish();
}

inline flatbuffers::Offset<Shape> CreateShapeDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<int64_t> *dim = nullptr) {
  auto dim__ = dim ? _fbb.CreateVector<int64_t>(*dim) : 0;
  return cvi::model::CreateShape(
      _fbb,
      dim__);
}

/// for symetric quant, only max_value is used (also called threshold)
struct QuantInfo FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef QuantInfoBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TYPE = 4,
    VT_MAX_VALUE = 6,
    VT_MIN_VALUE = 8,
    VT_ZERO_POINT = 10,
    VT_QSCALE = 12
  };
  cvi::model::QuantType type() const {
    return static_cast<cvi::model::QuantType>(GetField<uint8_t>(VT_TYPE, 0));
  }
  float max_value() const {
    return GetField<float>(VT_MAX_VALUE, 0.0f);
  }
  float min_value() const {
    return GetField<float>(VT_MIN_VALUE, 0.0f);
  }
  float zero_point() const {
    return GetField<float>(VT_ZERO_POINT, 0.0f);
  }
  float qscale() const {
    return GetField<float>(VT_QSCALE, 0.0f);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_TYPE) &&
           VerifyField<float>(verifier, VT_MAX_VALUE) &&
           VerifyField<float>(verifier, VT_MIN_VALUE) &&
           VerifyField<float>(verifier, VT_ZERO_POINT) &&
           VerifyField<float>(verifier, VT_QSCALE) &&
           verifier.EndTable();
  }
};

struct QuantInfoBuilder {
  typedef QuantInfo Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_type(cvi::model::QuantType type) {
    fbb_.AddElement<uint8_t>(QuantInfo::VT_TYPE, static_cast<uint8_t>(type), 0);
  }
  void add_max_value(float max_value) {
    fbb_.AddElement<float>(QuantInfo::VT_MAX_VALUE, max_value, 0.0f);
  }
  void add_min_value(float min_value) {
    fbb_.AddElement<float>(QuantInfo::VT_MIN_VALUE, min_value, 0.0f);
  }
  void add_zero_point(float zero_point) {
    fbb_.AddElement<float>(QuantInfo::VT_ZERO_POINT, zero_point, 0.0f);
  }
  void add_qscale(float qscale) {
    fbb_.AddElement<float>(QuantInfo::VT_QSCALE, qscale, 0.0f);
  }
  explicit QuantInfoBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  QuantInfoBuilder &operator=(const QuantInfoBuilder &);
  flatbuffers::Offset<QuantInfo> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<QuantInfo>(end);
    return o;
  }
};

inline flatbuffers::Offset<QuantInfo> CreateQuantInfo(
    flatbuffers::FlatBufferBuilder &_fbb,
    cvi::model::QuantType type = cvi::model::QuantType_NONE,
    float max_value = 0.0f,
    float min_value = 0.0f,
    float zero_point = 0.0f,
    float qscale = 0.0f) {
  QuantInfoBuilder builder_(_fbb);
  builder_.add_qscale(qscale);
  builder_.add_zero_point(zero_point);
  builder_.add_min_value(min_value);
  builder_.add_max_value(max_value);
  builder_.add_type(type);
  return builder_.Finish();
}

struct Tensor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TensorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TENSOR_ID = 4,
    VT_NAME = 6,
    VT_OFFSET = 8,
    VT_DTYPE = 10,
    VT_SHAPE = 12,
    VT_STRIDE = 14,
    VT_QUANT = 16,
    VT_OVERWROTE = 18,
    VT_SCALE = 20,
    VT_MEAN = 22,
    VT_PIXEL_FORMAT = 24,
    VT_ALIGNED = 26,
    VT_SIZE = 28
  };
  uint32_t tensor_id() const {
    return GetField<uint32_t>(VT_TENSOR_ID, 0);
  }
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  int64_t offset() const {
    return GetField<int64_t>(VT_OFFSET, 0);
  }
  cvi::model::DType dtype() const {
    return static_cast<cvi::model::DType>(GetField<uint8_t>(VT_DTYPE, 0));
  }
  const cvi::model::Shape *shape() const {
    return GetPointer<const cvi::model::Shape *>(VT_SHAPE);
  }
  const cvi::model::Shape *stride() const {
    return GetPointer<const cvi::model::Shape *>(VT_STRIDE);
  }
  const cvi::model::QuantInfo *quant() const {
    return GetPointer<const cvi::model::QuantInfo *>(VT_QUANT);
  }
  bool overwrote() const {
    return GetField<uint8_t>(VT_OVERWROTE, 0) != 0;
  }
  const flatbuffers::Vector<float> *scale() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_SCALE);
  }
  const flatbuffers::Vector<float> *mean() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_MEAN);
  }
  const flatbuffers::String *pixel_format() const {
    return GetPointer<const flatbuffers::String *>(VT_PIXEL_FORMAT);
  }
  bool aligned() const {
    return GetField<uint8_t>(VT_ALIGNED, 0) != 0;
  }
  uint32_t size() const {
    return GetField<uint32_t>(VT_SIZE, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_TENSOR_ID) &&
           VerifyOffsetRequired(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyField<int64_t>(verifier, VT_OFFSET) &&
           VerifyField<uint8_t>(verifier, VT_DTYPE) &&
           VerifyOffsetRequired(verifier, VT_SHAPE) &&
           verifier.VerifyTable(shape()) &&
           VerifyOffset(verifier, VT_STRIDE) &&
           verifier.VerifyTable(stride()) &&
           VerifyOffset(verifier, VT_QUANT) &&
           verifier.VerifyTable(quant()) &&
           VerifyField<uint8_t>(verifier, VT_OVERWROTE) &&
           VerifyOffset(verifier, VT_SCALE) &&
           verifier.VerifyVector(scale()) &&
           VerifyOffset(verifier, VT_MEAN) &&
           verifier.VerifyVector(mean()) &&
           VerifyOffset(verifier, VT_PIXEL_FORMAT) &&
           verifier.VerifyString(pixel_format()) &&
           VerifyField<uint8_t>(verifier, VT_ALIGNED) &&
           VerifyField<uint32_t>(verifier, VT_SIZE) &&
           verifier.EndTable();
  }
};

struct TensorBuilder {
  typedef Tensor Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_tensor_id(uint32_t tensor_id) {
    fbb_.AddElement<uint32_t>(Tensor::VT_TENSOR_ID, tensor_id, 0);
  }
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(Tensor::VT_NAME, name);
  }
  void add_offset(int64_t offset) {
    fbb_.AddElement<int64_t>(Tensor::VT_OFFSET, offset, 0);
  }
  void add_dtype(cvi::model::DType dtype) {
    fbb_.AddElement<uint8_t>(Tensor::VT_DTYPE, static_cast<uint8_t>(dtype), 0);
  }
  void add_shape(flatbuffers::Offset<cvi::model::Shape> shape) {
    fbb_.AddOffset(Tensor::VT_SHAPE, shape);
  }
  void add_stride(flatbuffers::Offset<cvi::model::Shape> stride) {
    fbb_.AddOffset(Tensor::VT_STRIDE, stride);
  }
  void add_quant(flatbuffers::Offset<cvi::model::QuantInfo> quant) {
    fbb_.AddOffset(Tensor::VT_QUANT, quant);
  }
  void add_overwrote(bool overwrote) {
    fbb_.AddElement<uint8_t>(Tensor::VT_OVERWROTE, static_cast<uint8_t>(overwrote), 0);
  }
  void add_scale(flatbuffers::Offset<flatbuffers::Vector<float>> scale) {
    fbb_.AddOffset(Tensor::VT_SCALE, scale);
  }
  void add_mean(flatbuffers::Offset<flatbuffers::Vector<float>> mean) {
    fbb_.AddOffset(Tensor::VT_MEAN, mean);
  }
  void add_pixel_format(flatbuffers::Offset<flatbuffers::String> pixel_format) {
    fbb_.AddOffset(Tensor::VT_PIXEL_FORMAT, pixel_format);
  }
  void add_aligned(bool aligned) {
    fbb_.AddElement<uint8_t>(Tensor::VT_ALIGNED, static_cast<uint8_t>(aligned), 0);
  }
  void add_size(uint32_t size) {
    fbb_.AddElement<uint32_t>(Tensor::VT_SIZE, size, 0);
  }
  explicit TensorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TensorBuilder &operator=(const TensorBuilder &);
  flatbuffers::Offset<Tensor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Tensor>(end);
    fbb_.Required(o, Tensor::VT_NAME);
    fbb_.Required(o, Tensor::VT_SHAPE);
    return o;
  }
};

inline flatbuffers::Offset<Tensor> CreateTensor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t tensor_id = 0,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    int64_t offset = 0,
    cvi::model::DType dtype = cvi::model::DType_FP32,
    flatbuffers::Offset<cvi::model::Shape> shape = 0,
    flatbuffers::Offset<cvi::model::Shape> stride = 0,
    flatbuffers::Offset<cvi::model::QuantInfo> quant = 0,
    bool overwrote = false,
    flatbuffers::Offset<flatbuffers::Vector<float>> scale = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> mean = 0,
    flatbuffers::Offset<flatbuffers::String> pixel_format = 0,
    bool aligned = false,
    uint32_t size = 0) {
  TensorBuilder builder_(_fbb);
  builder_.add_offset(offset);
  builder_.add_size(size);
  builder_.add_pixel_format(pixel_format);
  builder_.add_mean(mean);
  builder_.add_scale(scale);
  builder_.add_quant(quant);
  builder_.add_stride(stride);
  builder_.add_shape(shape);
  builder_.add_name(name);
  builder_.add_tensor_id(tensor_id);
  builder_.add_aligned(aligned);
  builder_.add_overwrote(overwrote);
  builder_.add_dtype(dtype);
  return builder_.Finish();
}

inline flatbuffers::Offset<Tensor> CreateTensorDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t tensor_id = 0,
    const char *name = nullptr,
    int64_t offset = 0,
    cvi::model::DType dtype = cvi::model::DType_FP32,
    flatbuffers::Offset<cvi::model::Shape> shape = 0,
    flatbuffers::Offset<cvi::model::Shape> stride = 0,
    flatbuffers::Offset<cvi::model::QuantInfo> quant = 0,
    bool overwrote = false,
    const std::vector<float> *scale = nullptr,
    const std::vector<float> *mean = nullptr,
    const char *pixel_format = nullptr,
    bool aligned = false,
    uint32_t size = 0) {
  auto name__ = name ? _fbb.CreateString(name) : 0;
  auto scale__ = scale ? _fbb.CreateVector<float>(*scale) : 0;
  auto mean__ = mean ? _fbb.CreateVector<float>(*mean) : 0;
  auto pixel_format__ = pixel_format ? _fbb.CreateString(pixel_format) : 0;
  return cvi::model::CreateTensor(
      _fbb,
      tensor_id,
      name__,
      offset,
      dtype,
      shape,
      stride,
      quant,
      overwrote,
      scale__,
      mean__,
      pixel_format__,
      aligned,
      size);
}

struct Weight FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef WeightBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NAME = 4,
    VT_OFFSET = 6,
    VT_SIZE = 8,
    VT_SHAPE = 10,
    VT_TYPE = 12
  };
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  int64_t offset() const {
    return GetField<int64_t>(VT_OFFSET, 0);
  }
  uint32_t size() const {
    return GetField<uint32_t>(VT_SIZE, 0);
  }
  const cvi::model::Shape *shape() const {
    return GetPointer<const cvi::model::Shape *>(VT_SHAPE);
  }
  cvi::model::DType type() const {
    return static_cast<cvi::model::DType>(GetField<uint8_t>(VT_TYPE, 0));
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyField<int64_t>(verifier, VT_OFFSET) &&
           VerifyField<uint32_t>(verifier, VT_SIZE) &&
           VerifyOffset(verifier, VT_SHAPE) &&
           verifier.VerifyTable(shape()) &&
           VerifyField<uint8_t>(verifier, VT_TYPE) &&
           verifier.EndTable();
  }
};

struct WeightBuilder {
  typedef Weight Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(Weight::VT_NAME, name);
  }
  void add_offset(int64_t offset) {
    fbb_.AddElement<int64_t>(Weight::VT_OFFSET, offset, 0);
  }
  void add_size(uint32_t size) {
    fbb_.AddElement<uint32_t>(Weight::VT_SIZE, size, 0);
  }
  void add_shape(flatbuffers::Offset<cvi::model::Shape> shape) {
    fbb_.AddOffset(Weight::VT_SHAPE, shape);
  }
  void add_type(cvi::model::DType type) {
    fbb_.AddElement<uint8_t>(Weight::VT_TYPE, static_cast<uint8_t>(type), 0);
  }
  explicit WeightBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  WeightBuilder &operator=(const WeightBuilder &);
  flatbuffers::Offset<Weight> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Weight>(end);
    return o;
  }
};

inline flatbuffers::Offset<Weight> CreateWeight(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    int64_t offset = 0,
    uint32_t size = 0,
    flatbuffers::Offset<cvi::model::Shape> shape = 0,
    cvi::model::DType type = cvi::model::DType_FP32) {
  WeightBuilder builder_(_fbb);
  builder_.add_offset(offset);
  builder_.add_shape(shape);
  builder_.add_size(size);
  builder_.add_name(name);
  builder_.add_type(type);
  return builder_.Finish();
}

inline flatbuffers::Offset<Weight> CreateWeightDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *name = nullptr,
    int64_t offset = 0,
    uint32_t size = 0,
    flatbuffers::Offset<cvi::model::Shape> shape = 0,
    cvi::model::DType type = cvi::model::DType_FP32) {
  auto name__ = name ? _fbb.CreateString(name) : 0;
  return cvi::model::CreateWeight(
      _fbb,
      name__,
      offset,
      size,
      shape,
      type);
}

///
/// color:
///   channel order for input image, valid values are `RGB`, `BGR`.
/// raw_scale:
///   a scale to apply before other proprocessing precedures
/// mean:
///   channel mean value, preprocess will substract the input by this value
/// std:
///   channel std value, preprocess will divide the input by this value
/// input_scale:
///   a scale to apply after other proprocessing precedures
///
struct PreProcessHints FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef PreProcessHintsBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_COLOR = 4,
    VT_RAW_SCALE = 6,
    VT_MEAN = 8,
    VT_STD = 10,
    VT_INPUT_SCALE = 12,
    VT_DATA_FORMAT = 14
  };
  const flatbuffers::String *color() const {
    return GetPointer<const flatbuffers::String *>(VT_COLOR);
  }
  float raw_scale() const {
    return GetField<float>(VT_RAW_SCALE, 0.0f);
  }
  const flatbuffers::String *mean() const {
    return GetPointer<const flatbuffers::String *>(VT_MEAN);
  }
  const flatbuffers::String *std() const {
    return GetPointer<const flatbuffers::String *>(VT_STD);
  }
  float input_scale() const {
    return GetField<float>(VT_INPUT_SCALE, 0.0f);
  }
  const flatbuffers::String *data_format() const {
    return GetPointer<const flatbuffers::String *>(VT_DATA_FORMAT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_COLOR) &&
           verifier.VerifyString(color()) &&
           VerifyField<float>(verifier, VT_RAW_SCALE) &&
           VerifyOffset(verifier, VT_MEAN) &&
           verifier.VerifyString(mean()) &&
           VerifyOffset(verifier, VT_STD) &&
           verifier.VerifyString(std()) &&
           VerifyField<float>(verifier, VT_INPUT_SCALE) &&
           VerifyOffset(verifier, VT_DATA_FORMAT) &&
           verifier.VerifyString(data_format()) &&
           verifier.EndTable();
  }
};

struct PreProcessHintsBuilder {
  typedef PreProcessHints Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_color(flatbuffers::Offset<flatbuffers::String> color) {
    fbb_.AddOffset(PreProcessHints::VT_COLOR, color);
  }
  void add_raw_scale(float raw_scale) {
    fbb_.AddElement<float>(PreProcessHints::VT_RAW_SCALE, raw_scale, 0.0f);
  }
  void add_mean(flatbuffers::Offset<flatbuffers::String> mean) {
    fbb_.AddOffset(PreProcessHints::VT_MEAN, mean);
  }
  void add_std(flatbuffers::Offset<flatbuffers::String> std) {
    fbb_.AddOffset(PreProcessHints::VT_STD, std);
  }
  void add_input_scale(float input_scale) {
    fbb_.AddElement<float>(PreProcessHints::VT_INPUT_SCALE, input_scale, 0.0f);
  }
  void add_data_format(flatbuffers::Offset<flatbuffers::String> data_format) {
    fbb_.AddOffset(PreProcessHints::VT_DATA_FORMAT, data_format);
  }
  explicit PreProcessHintsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  PreProcessHintsBuilder &operator=(const PreProcessHintsBuilder &);
  flatbuffers::Offset<PreProcessHints> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<PreProcessHints>(end);
    return o;
  }
};

inline flatbuffers::Offset<PreProcessHints> CreatePreProcessHints(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> color = 0,
    float raw_scale = 0.0f,
    flatbuffers::Offset<flatbuffers::String> mean = 0,
    flatbuffers::Offset<flatbuffers::String> std = 0,
    float input_scale = 0.0f,
    flatbuffers::Offset<flatbuffers::String> data_format = 0) {
  PreProcessHintsBuilder builder_(_fbb);
  builder_.add_data_format(data_format);
  builder_.add_input_scale(input_scale);
  builder_.add_std(std);
  builder_.add_mean(mean);
  builder_.add_raw_scale(raw_scale);
  builder_.add_color(color);
  return builder_.Finish();
}

inline flatbuffers::Offset<PreProcessHints> CreatePreProcessHintsDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *color = nullptr,
    float raw_scale = 0.0f,
    const char *mean = nullptr,
    const char *std = nullptr,
    float input_scale = 0.0f,
    const char *data_format = nullptr) {
  auto color__ = color ? _fbb.CreateString(color) : 0;
  auto mean__ = mean ? _fbb.CreateString(mean) : 0;
  auto std__ = std ? _fbb.CreateString(std) : 0;
  auto data_format__ = data_format ? _fbb.CreateString(data_format) : 0;
  return cvi::model::CreatePreProcessHints(
      _fbb,
      color__,
      raw_scale,
      mean__,
      std__,
      input_scale,
      data_format__);
}

struct PostProcessHints FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef PostProcessHintsBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DONE_SOFTMAX = 4
  };
  bool done_softmax() const {
    return GetField<uint8_t>(VT_DONE_SOFTMAX, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_DONE_SOFTMAX) &&
           verifier.EndTable();
  }
};

struct PostProcessHintsBuilder {
  typedef PostProcessHints Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_done_softmax(bool done_softmax) {
    fbb_.AddElement<uint8_t>(PostProcessHints::VT_DONE_SOFTMAX, static_cast<uint8_t>(done_softmax), 0);
  }
  explicit PostProcessHintsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  PostProcessHintsBuilder &operator=(const PostProcessHintsBuilder &);
  flatbuffers::Offset<PostProcessHints> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<PostProcessHints>(end);
    return o;
  }
};

inline flatbuffers::Offset<PostProcessHints> CreatePostProcessHints(
    flatbuffers::FlatBufferBuilder &_fbb,
    bool done_softmax = false) {
  PostProcessHintsBuilder builder_(_fbb);
  builder_.add_done_softmax(done_softmax);
  return builder_.Finish();
}

struct TpuRoutine FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TpuRoutineBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_CMDBUF_SECTION = 4,
    VT_DMABUF_SECTION = 6
  };
  const flatbuffers::String *cmdbuf_section() const {
    return GetPointer<const flatbuffers::String *>(VT_CMDBUF_SECTION);
  }
  const flatbuffers::String *dmabuf_section() const {
    return GetPointer<const flatbuffers::String *>(VT_DMABUF_SECTION);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_CMDBUF_SECTION) &&
           verifier.VerifyString(cmdbuf_section()) &&
           VerifyOffset(verifier, VT_DMABUF_SECTION) &&
           verifier.VerifyString(dmabuf_section()) &&
           verifier.EndTable();
  }
};

struct TpuRoutineBuilder {
  typedef TpuRoutine Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_cmdbuf_section(flatbuffers::Offset<flatbuffers::String> cmdbuf_section) {
    fbb_.AddOffset(TpuRoutine::VT_CMDBUF_SECTION, cmdbuf_section);
  }
  void add_dmabuf_section(flatbuffers::Offset<flatbuffers::String> dmabuf_section) {
    fbb_.AddOffset(TpuRoutine::VT_DMABUF_SECTION, dmabuf_section);
  }
  explicit TpuRoutineBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TpuRoutineBuilder &operator=(const TpuRoutineBuilder &);
  flatbuffers::Offset<TpuRoutine> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TpuRoutine>(end);
    return o;
  }
};

inline flatbuffers::Offset<TpuRoutine> CreateTpuRoutine(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> cmdbuf_section = 0,
    flatbuffers::Offset<flatbuffers::String> dmabuf_section = 0) {
  TpuRoutineBuilder builder_(_fbb);
  builder_.add_dmabuf_section(dmabuf_section);
  builder_.add_cmdbuf_section(cmdbuf_section);
  return builder_.Finish();
}

inline flatbuffers::Offset<TpuRoutine> CreateTpuRoutineDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *cmdbuf_section = nullptr,
    const char *dmabuf_section = nullptr) {
  auto cmdbuf_section__ = cmdbuf_section ? _fbb.CreateString(cmdbuf_section) : 0;
  auto dmabuf_section__ = dmabuf_section ? _fbb.CreateString(dmabuf_section) : 0;
  return cvi::model::CreateTpuRoutine(
      _fbb,
      cmdbuf_section__,
      dmabuf_section__);
}

struct CpuRoutine FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef CpuRoutineBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_FUNCTION_SECTION = 4,
    VT_FUNCTION_ARGS = 6
  };
  const flatbuffers::String *function_section() const {
    return GetPointer<const flatbuffers::String *>(VT_FUNCTION_SECTION);
  }
  const flatbuffers::Vector<uint8_t> *function_args() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_FUNCTION_ARGS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffsetRequired(verifier, VT_FUNCTION_SECTION) &&
           verifier.VerifyString(function_section()) &&
           VerifyOffsetRequired(verifier, VT_FUNCTION_ARGS) &&
           verifier.VerifyVector(function_args()) &&
           verifier.EndTable();
  }
};

struct CpuRoutineBuilder {
  typedef CpuRoutine Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_function_section(flatbuffers::Offset<flatbuffers::String> function_section) {
    fbb_.AddOffset(CpuRoutine::VT_FUNCTION_SECTION, function_section);
  }
  void add_function_args(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> function_args) {
    fbb_.AddOffset(CpuRoutine::VT_FUNCTION_ARGS, function_args);
  }
  explicit CpuRoutineBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  CpuRoutineBuilder &operator=(const CpuRoutineBuilder &);
  flatbuffers::Offset<CpuRoutine> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<CpuRoutine>(end);
    fbb_.Required(o, CpuRoutine::VT_FUNCTION_SECTION);
    fbb_.Required(o, CpuRoutine::VT_FUNCTION_ARGS);
    return o;
  }
};

inline flatbuffers::Offset<CpuRoutine> CreateCpuRoutine(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> function_section = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> function_args = 0) {
  CpuRoutineBuilder builder_(_fbb);
  builder_.add_function_args(function_args);
  builder_.add_function_section(function_section);
  return builder_.Finish();
}

inline flatbuffers::Offset<CpuRoutine> CreateCpuRoutineDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *function_section = nullptr,
    const std::vector<uint8_t> *function_args = nullptr) {
  auto function_section__ = function_section ? _fbb.CreateString(function_section) : 0;
  auto function_args__ = function_args ? _fbb.CreateVector<uint8_t>(*function_args) : 0;
  return cvi::model::CreateCpuRoutine(
      _fbb,
      function_section__,
      function_args__);
}

struct Routine FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef RoutineBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TYPE = 4,
    VT_IN_TENSORS = 6,
    VT_OUT_TENSORS = 8,
    VT_TPU_ROUTINE = 10,
    VT_CPU_ROUTINE = 12
  };
  cvi::model::RoutineType type() const {
    return static_cast<cvi::model::RoutineType>(GetField<uint8_t>(VT_TYPE, 0));
  }
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *in_tensors() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_IN_TENSORS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *out_tensors() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_OUT_TENSORS);
  }
  const cvi::model::TpuRoutine *tpu_routine() const {
    return GetPointer<const cvi::model::TpuRoutine *>(VT_TPU_ROUTINE);
  }
  const cvi::model::CpuRoutine *cpu_routine() const {
    return GetPointer<const cvi::model::CpuRoutine *>(VT_CPU_ROUTINE);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_TYPE) &&
           VerifyOffset(verifier, VT_IN_TENSORS) &&
           verifier.VerifyVector(in_tensors()) &&
           verifier.VerifyVectorOfStrings(in_tensors()) &&
           VerifyOffset(verifier, VT_OUT_TENSORS) &&
           verifier.VerifyVector(out_tensors()) &&
           verifier.VerifyVectorOfStrings(out_tensors()) &&
           VerifyOffset(verifier, VT_TPU_ROUTINE) &&
           verifier.VerifyTable(tpu_routine()) &&
           VerifyOffset(verifier, VT_CPU_ROUTINE) &&
           verifier.VerifyTable(cpu_routine()) &&
           verifier.EndTable();
  }
};

struct RoutineBuilder {
  typedef Routine Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_type(cvi::model::RoutineType type) {
    fbb_.AddElement<uint8_t>(Routine::VT_TYPE, static_cast<uint8_t>(type), 0);
  }
  void add_in_tensors(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> in_tensors) {
    fbb_.AddOffset(Routine::VT_IN_TENSORS, in_tensors);
  }
  void add_out_tensors(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> out_tensors) {
    fbb_.AddOffset(Routine::VT_OUT_TENSORS, out_tensors);
  }
  void add_tpu_routine(flatbuffers::Offset<cvi::model::TpuRoutine> tpu_routine) {
    fbb_.AddOffset(Routine::VT_TPU_ROUTINE, tpu_routine);
  }
  void add_cpu_routine(flatbuffers::Offset<cvi::model::CpuRoutine> cpu_routine) {
    fbb_.AddOffset(Routine::VT_CPU_ROUTINE, cpu_routine);
  }
  explicit RoutineBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  RoutineBuilder &operator=(const RoutineBuilder &);
  flatbuffers::Offset<Routine> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Routine>(end);
    return o;
  }
};

inline flatbuffers::Offset<Routine> CreateRoutine(
    flatbuffers::FlatBufferBuilder &_fbb,
    cvi::model::RoutineType type = cvi::model::RoutineType_TPU,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> in_tensors = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> out_tensors = 0,
    flatbuffers::Offset<cvi::model::TpuRoutine> tpu_routine = 0,
    flatbuffers::Offset<cvi::model::CpuRoutine> cpu_routine = 0) {
  RoutineBuilder builder_(_fbb);
  builder_.add_cpu_routine(cpu_routine);
  builder_.add_tpu_routine(tpu_routine);
  builder_.add_out_tensors(out_tensors);
  builder_.add_in_tensors(in_tensors);
  builder_.add_type(type);
  return builder_.Finish();
}

inline flatbuffers::Offset<Routine> CreateRoutineDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    cvi::model::RoutineType type = cvi::model::RoutineType_TPU,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *in_tensors = nullptr,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *out_tensors = nullptr,
    flatbuffers::Offset<cvi::model::TpuRoutine> tpu_routine = 0,
    flatbuffers::Offset<cvi::model::CpuRoutine> cpu_routine = 0) {
  auto in_tensors__ = in_tensors ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*in_tensors) : 0;
  auto out_tensors__ = out_tensors ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*out_tensors) : 0;
  return cvi::model::CreateRoutine(
      _fbb,
      type,
      in_tensors__,
      out_tensors__,
      tpu_routine,
      cpu_routine);
}

struct Program FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ProgramBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_BATCH_NUM = 4,
    VT_NEURON_SIZE = 6,
    VT_INPUT_TENSORS = 8,
    VT_OUTPUT_TENSORS = 10,
    VT_TENSOR_MAP = 12,
    VT_ROUTINES = 14,
    VT_SHARED_GMEM = 16,
    VT_PRIVATE_GMEM = 18
  };
  uint32_t batch_num() const {
    return GetField<uint32_t>(VT_BATCH_NUM, 0);
  }
  uint32_t neuron_size() const {
    return GetField<uint32_t>(VT_NEURON_SIZE, 0);
  }
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *input_tensors() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_INPUT_TENSORS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *output_tensors() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_OUTPUT_TENSORS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<cvi::model::Tensor>> *tensor_map() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<cvi::model::Tensor>> *>(VT_TENSOR_MAP);
  }
  const flatbuffers::Vector<flatbuffers::Offset<cvi::model::Routine>> *routines() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<cvi::model::Routine>> *>(VT_ROUTINES);
  }
  uint32_t shared_gmem() const {
    return GetField<uint32_t>(VT_SHARED_GMEM, 0);
  }
  uint32_t private_gmem() const {
    return GetField<uint32_t>(VT_PRIVATE_GMEM, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_BATCH_NUM) &&
           VerifyField<uint32_t>(verifier, VT_NEURON_SIZE) &&
           VerifyOffsetRequired(verifier, VT_INPUT_TENSORS) &&
           verifier.VerifyVector(input_tensors()) &&
           verifier.VerifyVectorOfStrings(input_tensors()) &&
           VerifyOffsetRequired(verifier, VT_OUTPUT_TENSORS) &&
           verifier.VerifyVector(output_tensors()) &&
           verifier.VerifyVectorOfStrings(output_tensors()) &&
           VerifyOffsetRequired(verifier, VT_TENSOR_MAP) &&
           verifier.VerifyVector(tensor_map()) &&
           verifier.VerifyVectorOfTables(tensor_map()) &&
           VerifyOffsetRequired(verifier, VT_ROUTINES) &&
           verifier.VerifyVector(routines()) &&
           verifier.VerifyVectorOfTables(routines()) &&
           VerifyField<uint32_t>(verifier, VT_SHARED_GMEM) &&
           VerifyField<uint32_t>(verifier, VT_PRIVATE_GMEM) &&
           verifier.EndTable();
  }
};

struct ProgramBuilder {
  typedef Program Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_batch_num(uint32_t batch_num) {
    fbb_.AddElement<uint32_t>(Program::VT_BATCH_NUM, batch_num, 0);
  }
  void add_neuron_size(uint32_t neuron_size) {
    fbb_.AddElement<uint32_t>(Program::VT_NEURON_SIZE, neuron_size, 0);
  }
  void add_input_tensors(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> input_tensors) {
    fbb_.AddOffset(Program::VT_INPUT_TENSORS, input_tensors);
  }
  void add_output_tensors(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> output_tensors) {
    fbb_.AddOffset(Program::VT_OUTPUT_TENSORS, output_tensors);
  }
  void add_tensor_map(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<cvi::model::Tensor>>> tensor_map) {
    fbb_.AddOffset(Program::VT_TENSOR_MAP, tensor_map);
  }
  void add_routines(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<cvi::model::Routine>>> routines) {
    fbb_.AddOffset(Program::VT_ROUTINES, routines);
  }
  void add_shared_gmem(uint32_t shared_gmem) {
    fbb_.AddElement<uint32_t>(Program::VT_SHARED_GMEM, shared_gmem, 0);
  }
  void add_private_gmem(uint32_t private_gmem) {
    fbb_.AddElement<uint32_t>(Program::VT_PRIVATE_GMEM, private_gmem, 0);
  }
  explicit ProgramBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ProgramBuilder &operator=(const ProgramBuilder &);
  flatbuffers::Offset<Program> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Program>(end);
    fbb_.Required(o, Program::VT_INPUT_TENSORS);
    fbb_.Required(o, Program::VT_OUTPUT_TENSORS);
    fbb_.Required(o, Program::VT_TENSOR_MAP);
    fbb_.Required(o, Program::VT_ROUTINES);
    return o;
  }
};

inline flatbuffers::Offset<Program> CreateProgram(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t batch_num = 0,
    uint32_t neuron_size = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> input_tensors = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> output_tensors = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<cvi::model::Tensor>>> tensor_map = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<cvi::model::Routine>>> routines = 0,
    uint32_t shared_gmem = 0,
    uint32_t private_gmem = 0) {
  ProgramBuilder builder_(_fbb);
  builder_.add_private_gmem(private_gmem);
  builder_.add_shared_gmem(shared_gmem);
  builder_.add_routines(routines);
  builder_.add_tensor_map(tensor_map);
  builder_.add_output_tensors(output_tensors);
  builder_.add_input_tensors(input_tensors);
  builder_.add_neuron_size(neuron_size);
  builder_.add_batch_num(batch_num);
  return builder_.Finish();
}

inline flatbuffers::Offset<Program> CreateProgramDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t batch_num = 0,
    uint32_t neuron_size = 0,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *input_tensors = nullptr,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *output_tensors = nullptr,
    const std::vector<flatbuffers::Offset<cvi::model::Tensor>> *tensor_map = nullptr,
    const std::vector<flatbuffers::Offset<cvi::model::Routine>> *routines = nullptr,
    uint32_t shared_gmem = 0,
    uint32_t private_gmem = 0) {
  auto input_tensors__ = input_tensors ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*input_tensors) : 0;
  auto output_tensors__ = output_tensors ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*output_tensors) : 0;
  auto tensor_map__ = tensor_map ? _fbb.CreateVector<flatbuffers::Offset<cvi::model::Tensor>>(*tensor_map) : 0;
  auto routines__ = routines ? _fbb.CreateVector<flatbuffers::Offset<cvi::model::Routine>>(*routines) : 0;
  return cvi::model::CreateProgram(
      _fbb,
      batch_num,
      neuron_size,
      input_tensors__,
      output_tensors__,
      tensor_map__,
      routines__,
      shared_gmem,
      private_gmem);
}

struct Section FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef SectionBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TYPE = 4,
    VT_NAME = 6,
    VT_SIZE = 8,
    VT_OFFSET = 10,
    VT_ENCRYPT = 12,
    VT_COMPRESS = 14,
    VT_DECOMPRESSED_SIZE = 16
  };
  cvi::model::SectionType type() const {
    return static_cast<cvi::model::SectionType>(GetField<uint8_t>(VT_TYPE, 0));
  }
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  uint32_t size() const {
    return GetField<uint32_t>(VT_SIZE, 0);
  }
  uint32_t offset() const {
    return GetField<uint32_t>(VT_OFFSET, 0);
  }
  bool encrypt() const {
    return GetField<uint8_t>(VT_ENCRYPT, 0) != 0;
  }
  bool compress() const {
    return GetField<uint8_t>(VT_COMPRESS, 0) != 0;
  }
  uint32_t decompressed_size() const {
    return GetField<uint32_t>(VT_DECOMPRESSED_SIZE, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_TYPE) &&
           VerifyOffsetRequired(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyField<uint32_t>(verifier, VT_SIZE) &&
           VerifyField<uint32_t>(verifier, VT_OFFSET) &&
           VerifyField<uint8_t>(verifier, VT_ENCRYPT) &&
           VerifyField<uint8_t>(verifier, VT_COMPRESS) &&
           VerifyField<uint32_t>(verifier, VT_DECOMPRESSED_SIZE) &&
           verifier.EndTable();
  }
};

struct SectionBuilder {
  typedef Section Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_type(cvi::model::SectionType type) {
    fbb_.AddElement<uint8_t>(Section::VT_TYPE, static_cast<uint8_t>(type), 0);
  }
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(Section::VT_NAME, name);
  }
  void add_size(uint32_t size) {
    fbb_.AddElement<uint32_t>(Section::VT_SIZE, size, 0);
  }
  void add_offset(uint32_t offset) {
    fbb_.AddElement<uint32_t>(Section::VT_OFFSET, offset, 0);
  }
  void add_encrypt(bool encrypt) {
    fbb_.AddElement<uint8_t>(Section::VT_ENCRYPT, static_cast<uint8_t>(encrypt), 0);
  }
  void add_compress(bool compress) {
    fbb_.AddElement<uint8_t>(Section::VT_COMPRESS, static_cast<uint8_t>(compress), 0);
  }
  void add_decompressed_size(uint32_t decompressed_size) {
    fbb_.AddElement<uint32_t>(Section::VT_DECOMPRESSED_SIZE, decompressed_size, 0);
  }
  explicit SectionBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  SectionBuilder &operator=(const SectionBuilder &);
  flatbuffers::Offset<Section> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Section>(end);
    fbb_.Required(o, Section::VT_NAME);
    return o;
  }
};

inline flatbuffers::Offset<Section> CreateSection(
    flatbuffers::FlatBufferBuilder &_fbb,
    cvi::model::SectionType type = cvi::model::SectionType_WEIGHT,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    uint32_t size = 0,
    uint32_t offset = 0,
    bool encrypt = false,
    bool compress = false,
    uint32_t decompressed_size = 0) {
  SectionBuilder builder_(_fbb);
  builder_.add_decompressed_size(decompressed_size);
  builder_.add_offset(offset);
  builder_.add_size(size);
  builder_.add_name(name);
  builder_.add_compress(compress);
  builder_.add_encrypt(encrypt);
  builder_.add_type(type);
  return builder_.Finish();
}

inline flatbuffers::Offset<Section> CreateSectionDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    cvi::model::SectionType type = cvi::model::SectionType_WEIGHT,
    const char *name = nullptr,
    uint32_t size = 0,
    uint32_t offset = 0,
    bool encrypt = false,
    bool compress = false,
    uint32_t decompressed_size = 0) {
  auto name__ = name ? _fbb.CreateString(name) : 0;
  return cvi::model::CreateSection(
      _fbb,
      type,
      name__,
      size,
      offset,
      encrypt,
      compress,
      decompressed_size);
}

struct Model FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ModelBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VERSION = 4,
    VT_NAME = 6,
    VT_BUILD_TIME = 8,
    VT_PREPROCESS_HINTS = 10,
    VT_POSTPROCESS_HINTS = 12,
    VT_WEIGHT_MAP = 14,
    VT_PROGRAMS = 16,
    VT_SECTIONS = 18,
    VT_TARGET = 20,
    VT_MLIR_VERSION = 22
  };
  const cvi::model::Version *version() const {
    return GetStruct<const cvi::model::Version *>(VT_VERSION);
  }
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  const flatbuffers::String *build_time() const {
    return GetPointer<const flatbuffers::String *>(VT_BUILD_TIME);
  }
  const cvi::model::PreProcessHints *preprocess_hints() const {
    return GetPointer<const cvi::model::PreProcessHints *>(VT_PREPROCESS_HINTS);
  }
  const cvi::model::PostProcessHints *postprocess_hints() const {
    return GetPointer<const cvi::model::PostProcessHints *>(VT_POSTPROCESS_HINTS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<cvi::model::Weight>> *weight_map() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<cvi::model::Weight>> *>(VT_WEIGHT_MAP);
  }
  const flatbuffers::Vector<flatbuffers::Offset<cvi::model::Program>> *programs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<cvi::model::Program>> *>(VT_PROGRAMS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<cvi::model::Section>> *sections() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<cvi::model::Section>> *>(VT_SECTIONS);
  }
  const flatbuffers::String *target() const {
    return GetPointer<const flatbuffers::String *>(VT_TARGET);
  }
  const flatbuffers::String *mlir_version() const {
    return GetPointer<const flatbuffers::String *>(VT_MLIR_VERSION);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyFieldRequired<cvi::model::Version>(verifier, VT_VERSION) &&
           VerifyOffsetRequired(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyOffset(verifier, VT_BUILD_TIME) &&
           verifier.VerifyString(build_time()) &&
           VerifyOffset(verifier, VT_PREPROCESS_HINTS) &&
           verifier.VerifyTable(preprocess_hints()) &&
           VerifyOffset(verifier, VT_POSTPROCESS_HINTS) &&
           verifier.VerifyTable(postprocess_hints()) &&
           VerifyOffset(verifier, VT_WEIGHT_MAP) &&
           verifier.VerifyVector(weight_map()) &&
           verifier.VerifyVectorOfTables(weight_map()) &&
           VerifyOffsetRequired(verifier, VT_PROGRAMS) &&
           verifier.VerifyVector(programs()) &&
           verifier.VerifyVectorOfTables(programs()) &&
           VerifyOffsetRequired(verifier, VT_SECTIONS) &&
           verifier.VerifyVector(sections()) &&
           verifier.VerifyVectorOfTables(sections()) &&
           VerifyOffset(verifier, VT_TARGET) &&
           verifier.VerifyString(target()) &&
           VerifyOffset(verifier, VT_MLIR_VERSION) &&
           verifier.VerifyString(mlir_version()) &&
           verifier.EndTable();
  }
};

struct ModelBuilder {
  typedef Model Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_version(const cvi::model::Version *version) {
    fbb_.AddStruct(Model::VT_VERSION, version);
  }
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(Model::VT_NAME, name);
  }
  void add_build_time(flatbuffers::Offset<flatbuffers::String> build_time) {
    fbb_.AddOffset(Model::VT_BUILD_TIME, build_time);
  }
  void add_preprocess_hints(flatbuffers::Offset<cvi::model::PreProcessHints> preprocess_hints) {
    fbb_.AddOffset(Model::VT_PREPROCESS_HINTS, preprocess_hints);
  }
  void add_postprocess_hints(flatbuffers::Offset<cvi::model::PostProcessHints> postprocess_hints) {
    fbb_.AddOffset(Model::VT_POSTPROCESS_HINTS, postprocess_hints);
  }
  void add_weight_map(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<cvi::model::Weight>>> weight_map) {
    fbb_.AddOffset(Model::VT_WEIGHT_MAP, weight_map);
  }
  void add_programs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<cvi::model::Program>>> programs) {
    fbb_.AddOffset(Model::VT_PROGRAMS, programs);
  }
  void add_sections(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<cvi::model::Section>>> sections) {
    fbb_.AddOffset(Model::VT_SECTIONS, sections);
  }
  void add_target(flatbuffers::Offset<flatbuffers::String> target) {
    fbb_.AddOffset(Model::VT_TARGET, target);
  }
  void add_mlir_version(flatbuffers::Offset<flatbuffers::String> mlir_version) {
    fbb_.AddOffset(Model::VT_MLIR_VERSION, mlir_version);
  }
  explicit ModelBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ModelBuilder &operator=(const ModelBuilder &);
  flatbuffers::Offset<Model> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Model>(end);
    fbb_.Required(o, Model::VT_VERSION);
    fbb_.Required(o, Model::VT_NAME);
    fbb_.Required(o, Model::VT_PROGRAMS);
    fbb_.Required(o, Model::VT_SECTIONS);
    return o;
  }
};

inline flatbuffers::Offset<Model> CreateModel(
    flatbuffers::FlatBufferBuilder &_fbb,
    const cvi::model::Version *version = 0,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    flatbuffers::Offset<flatbuffers::String> build_time = 0,
    flatbuffers::Offset<cvi::model::PreProcessHints> preprocess_hints = 0,
    flatbuffers::Offset<cvi::model::PostProcessHints> postprocess_hints = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<cvi::model::Weight>>> weight_map = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<cvi::model::Program>>> programs = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<cvi::model::Section>>> sections = 0,
    flatbuffers::Offset<flatbuffers::String> target = 0,
    flatbuffers::Offset<flatbuffers::String> mlir_version = 0) {
  ModelBuilder builder_(_fbb);
  builder_.add_mlir_version(mlir_version);
  builder_.add_target(target);
  builder_.add_sections(sections);
  builder_.add_programs(programs);
  builder_.add_weight_map(weight_map);
  builder_.add_postprocess_hints(postprocess_hints);
  builder_.add_preprocess_hints(preprocess_hints);
  builder_.add_build_time(build_time);
  builder_.add_name(name);
  builder_.add_version(version);
  return builder_.Finish();
}

inline flatbuffers::Offset<Model> CreateModelDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const cvi::model::Version *version = 0,
    const char *name = nullptr,
    const char *build_time = nullptr,
    flatbuffers::Offset<cvi::model::PreProcessHints> preprocess_hints = 0,
    flatbuffers::Offset<cvi::model::PostProcessHints> postprocess_hints = 0,
    const std::vector<flatbuffers::Offset<cvi::model::Weight>> *weight_map = nullptr,
    const std::vector<flatbuffers::Offset<cvi::model::Program>> *programs = nullptr,
    const std::vector<flatbuffers::Offset<cvi::model::Section>> *sections = nullptr,
    const char *target = nullptr,
    const char *mlir_version = nullptr) {
  auto name__ = name ? _fbb.CreateString(name) : 0;
  auto build_time__ = build_time ? _fbb.CreateString(build_time) : 0;
  auto weight_map__ = weight_map ? _fbb.CreateVector<flatbuffers::Offset<cvi::model::Weight>>(*weight_map) : 0;
  auto programs__ = programs ? _fbb.CreateVector<flatbuffers::Offset<cvi::model::Program>>(*programs) : 0;
  auto sections__ = sections ? _fbb.CreateVector<flatbuffers::Offset<cvi::model::Section>>(*sections) : 0;
  auto target__ = target ? _fbb.CreateString(target) : 0;
  auto mlir_version__ = mlir_version ? _fbb.CreateString(mlir_version) : 0;
  return cvi::model::CreateModel(
      _fbb,
      version,
      name__,
      build_time__,
      preprocess_hints,
      postprocess_hints,
      weight_map__,
      programs__,
      sections__,
      target__,
      mlir_version__);
}

inline const cvi::model::Model *GetModel(const void *buf) {
  return flatbuffers::GetRoot<cvi::model::Model>(buf);
}

inline const cvi::model::Model *GetSizePrefixedModel(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<cvi::model::Model>(buf);
}

inline bool VerifyModelBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<cvi::model::Model>(nullptr);
}

inline bool VerifySizePrefixedModelBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<cvi::model::Model>(nullptr);
}

inline void FinishModelBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<cvi::model::Model> root) {
  fbb.Finish(root);
}

inline void FinishSizePrefixedModelBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<cvi::model::Model> root) {
  fbb.FinishSizePrefixed(root);
}

}  // namespace model
}  // namespace cvi

#endif  // FLATBUFFERS_GENERATED_CVIMODEL_CVI_MODEL_H_
